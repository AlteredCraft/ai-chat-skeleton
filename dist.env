# Anthropic API Configuration
ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY

# Logging Configuration
LOG_LEVEL=INFO

# Claude Model Parameters
# Model to use for chat completions
ANTHROPIC_MODEL=claude-haiku-4-5-20251001

# Maximum tokens to generate in the response (default: 1024)
ANTHROPIC_MAX_TOKENS=1024

# Temperature controls randomness (0.0-1.0, default: 1.0)
# Lower = more focused/deterministic, Higher = more creative/random
ANTHROPIC_TEMPERATURE=1.0

# Top-p nucleus sampling (0.0-1.0, optional)
# Alternative to temperature. Only sample from top tokens with cumulative probability p
# ANTHROPIC_TOP_P=0.9

# Top-k sampling (optional)
# Only sample from the k most likely tokens
# ANTHROPIC_TOP_K=40

# System prompt (optional)
# Provides context and instructions to the model
# ANTHROPIC_SYSTEM_PROMPT=You are a helpful assistant.

# Stop sequences (optional, comma-separated)
# Model will stop generating when it encounters these sequences
# ANTHROPIC_STOP_SEQUENCES=\n\nHuman:,\n\nAssistant:
